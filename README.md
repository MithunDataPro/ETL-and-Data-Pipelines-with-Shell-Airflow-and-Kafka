# ETL and Data Pipelines with Shell, Airflow, and Kafka

**ETL** stands for **Extract, Transform, and Load**. It refers to the process of curating data from multiple sources and preparing the data for integration and loading into a destination platform such as a data warehouse or analytics environment. 

**ELT** is similar but loads the data in its raw format, reserving the transformations for people to apply themselves in a ‘self-serve analytics’ destination environment. 

Both methods are typical examples of data pipeline deployments.

![image](https://github.com/user-attachments/assets/93970921-a80a-426b-9530-08935d20ece8)
